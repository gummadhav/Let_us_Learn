{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGJuMHmAh02XZZJYPY4LhU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gummadhav/Let_us_Learn/blob/main/CUDA_Streams_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nz9gPauJLaHk"
      },
      "outputs": [],
      "source": [
        "%%shell\n",
        "%%shell\n",
        "# Update package lists\n",
        "apt-get update\n",
        "\n",
        "# Install essential build tools (if not already present, good practice)\n",
        "apt-get install -y build-essential\n",
        "\n",
        "# Install OpenCV development libraries (C++ headers and shared libraries)\n",
        "# 'libopencv-dev' provides the development files\n",
        "# 'python3-opencv' is for Python, but sometimes pulled in as a dependency\n",
        "apt-get install -y libopencv-dev python3-opencv\n",
        "\n",
        "# Verify OpenCV version (optional, but good for checking)\n",
        "pkg-config --modversion opencv4 # For OpenCV 4.x\n",
        "# Or for older versions: pkg-config --modversion opencv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nvcc4jupyter"
      ],
      "metadata": {
        "id": "UnnxLRDjuKRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc4jupyter"
      ],
      "metadata": {
        "id": "G7XM0QtJuNHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvcc --version"
      ],
      "metadata": {
        "id": "M3DplYFyuPoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "nvidia-smi"
      ],
      "metadata": {
        "id": "-2q0wL7SuUeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile gpu_with_threaded_CUDA_Streams.cu\n",
        "\n",
        "#include <opencv2/opencv.hpp>\n",
        "#include <vector>\n",
        "#include <string>\n",
        "#include <filesystem>\n",
        "#include <iostream>\n",
        "#include <queue>\n",
        "#include <mutex>\n",
        "#include <thread>\n",
        "#include <atomic>\n",
        "#include \"cuda_runtime.h\"\n",
        "\n",
        "#define MAX_STREAMS 4\n",
        "\n",
        "// Utility: get image paths from folder\n",
        "std::vector<std::string> get_image_paths(const std::string& folder) {\n",
        "    std::vector<std::string> paths;\n",
        "    for (const auto& entry : std::filesystem::directory_iterator(folder)) {\n",
        "        if (entry.path().extension() == \".bmp\") {\n",
        "            paths.push_back(entry.path().string());\n",
        "        }\n",
        "    }\n",
        "    return paths;\n",
        "}\n",
        "\n",
        "// CUDA Gaussian Filter kernel\n",
        "__global__\n",
        "void gaussian_filter_kernel(const uchar* input, uchar* output, int width, int height, const float* kernel) {\n",
        "    int x = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int y = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    if (x >= width || y >= height) return;\n",
        "    float sum = 0, kSum = 0;\n",
        "    for (int dy = -1; dy <= 1; ++dy) {\n",
        "        for (int dx = -1; dx <= 1; ++dx) {\n",
        "            int ix = min(max(x+dx,0), width-1);\n",
        "            int iy = min(max(y+dy,0), height-1);\n",
        "            float k = kernel[(dy+1)*3 + (dx+1)];\n",
        "            sum += input[iy*width + ix] * k;\n",
        "            kSum += k;\n",
        "        }\n",
        "    }\n",
        "    float result = kSum > 0 ? sum / kSum : 0;\n",
        "    result = min(max(result, 0.0f), 255.0f);\n",
        "    output[y*width + x] = static_cast<uchar>(result);\n",
        "}\n",
        "\n",
        "__global__\n",
        "void laplacian_filter_kernel(const uchar* input, uchar* output, int width, int height) {\n",
        "    int kernel[3][3] = { {-1,-1,-1}, {-1,8,-1}, {-1,-1,-1} };\n",
        "    int x = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int y = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    if (x >= width || y >= height) return;\n",
        "    int sum = 0;\n",
        "    for (int dy = -1; dy <= 1; ++dy) {\n",
        "        for (int dx = -1; dx <= 1; ++dx) {\n",
        "            int ix = min(max(x+dx,0), width-1);\n",
        "            int iy = min(max(y+dy,0), height-1);\n",
        "            sum += input[iy*width + ix] * kernel[dy+1][dx+1];\n",
        "        }\n",
        "    }\n",
        "    int result = sum + 128;\n",
        "    result = min(max(result, 0), 255);\n",
        "    output[y*width + x] = static_cast<uchar>(result);\n",
        "}\n",
        "\n",
        "#define CHECK_CUDA(call) \\\n",
        "    { \\\n",
        "        cudaError_t err = call; \\\n",
        "        if (err != cudaSuccess) { \\\n",
        "            std::cerr << \"CUDA error: \" << cudaGetErrorString(err) << \" at \" << __FILE__ << \":\" << __LINE__ << std::endl; \\\n",
        "            exit(1); \\\n",
        "        } \\\n",
        "    }\n",
        "\n",
        "// Empty kernel for warm-up\n",
        "__global__ void empty_kernel(int* p) { *p = 1; }\n",
        "\n",
        "// Warm-up function\n",
        "void warm_up() {\n",
        "    std::cout << \"Warming up CUDA...\" << std::endl;\n",
        "    int* d_temp;\n",
        "    CHECK_CUDA(cudaMalloc(&d_temp, sizeof(int)));\n",
        "    empty_kernel<<<1, 1>>>(d_temp);  // Launch any small dummy kernel\n",
        "    CHECK_CUDA(cudaDeviceSynchronize());\n",
        "    CHECK_CUDA(cudaFree(d_temp));\n",
        "    std::cout << \"Warm-up complete.\" << std::endl;\n",
        "}\n",
        "\n",
        "// Buffer struct per image\n",
        "struct DeviceBuffers {\n",
        "    uchar *d_input = nullptr, *d_gauss = nullptr, *d_laplace = nullptr;\n",
        "    float *d_gkernel = nullptr;\n",
        "    cudaStream_t stream = nullptr;\n",
        "    cudaEvent_t event_start = nullptr, event_stop = nullptr;\n",
        "    int width = 0, height = 0;\n",
        "    size_t size = 0;\n",
        "};\n",
        "\n",
        "std::queue<std::string> image_queue;\n",
        "std::mutex queue_mutex;\n",
        "std::atomic<int> images_processed(0);\n",
        "\n",
        "// Per-image GPU worker\n",
        "void process_image_gpu(const std::string& path, const float* gaussKernel, const std::string& output_folder) {\n",
        "    cv::Mat img = cv::imread(path, cv::IMREAD_GRAYSCALE);\n",
        "    if (img.empty() || img.type() != CV_8U || img.channels() != 1) {\n",
        "        std::cerr << \"Invalid image: \" << path << std::endl;\n",
        "        return;\n",
        "    }\n",
        "    int width = img.cols, height = img.rows;\n",
        "    size_t size = width * height * sizeof(uchar);\n",
        "\n",
        "    // Allocate device buffers and stream/events\n",
        "    DeviceBuffers db;\n",
        "    db.width = width;\n",
        "    db.height = height;\n",
        "    db.size = size;\n",
        "\n",
        "    CHECK_CUDA(cudaMalloc(&db.d_input, size));\n",
        "    CHECK_CUDA(cudaMalloc(&db.d_gauss, size));\n",
        "    CHECK_CUDA(cudaMalloc(&db.d_laplace, size));\n",
        "    CHECK_CUDA(cudaMalloc(&db.d_gkernel, 9 * sizeof(float)));\n",
        "\n",
        "    CHECK_CUDA(cudaStreamCreate(&db.stream));\n",
        "    CHECK_CUDA(cudaEventCreate(&db.event_start));\n",
        "    CHECK_CUDA(cudaEventCreate(&db.event_stop));\n",
        "\n",
        "    // Copy data to device asynchronously\n",
        "    CHECK_CUDA(cudaMemcpyAsync(db.d_input, img.data, size, cudaMemcpyHostToDevice, db.stream));\n",
        "    CHECK_CUDA(cudaMemcpyAsync(db.d_gkernel, gaussKernel, 9 * sizeof(float), cudaMemcpyHostToDevice, db.stream));\n",
        "\n",
        "    dim3 block(16,16), grid((width+15)/16, (height+15)/16);\n",
        "\n",
        "    // Timing start\n",
        "    CHECK_CUDA(cudaEventRecord(db.event_start, db.stream));\n",
        "\n",
        "    gaussian_filter_kernel<<<grid, block, 0, db.stream>>>(db.d_input, db.d_gauss, width, height, db.d_gkernel);\n",
        "    laplacian_filter_kernel<<<grid, block, 0, db.stream>>>(db.d_gauss, db.d_laplace, width, height);\n",
        "\n",
        "    // Timing stop\n",
        "    CHECK_CUDA(cudaEventRecord(db.event_stop, db.stream));\n",
        "    CHECK_CUDA(cudaGetLastError()); // Check for kernel errors after recording stop event\n",
        "\n",
        "    // Copy output to host asynchronously\n",
        "    cv::Mat out(height, width, CV_8U);\n",
        "    CHECK_CUDA(cudaMemcpyAsync(out.data, db.d_laplace, size, cudaMemcpyDeviceToHost, db.stream));\n",
        "\n",
        "    // Wait for all GPU operations\n",
        "    CHECK_CUDA(cudaStreamSynchronize(db.stream));\n",
        "    CHECK_CUDA(cudaGetLastError());\n",
        "\n",
        "    // Timing calculation\n",
        "    float kernel_ms = 0;\n",
        "    CHECK_CUDA(cudaEventElapsedTime(&kernel_ms, db.event_start, db.event_stop));\n",
        "\n",
        "    // Save the image\n",
        "    std::string gpu_output = output_folder + \"/\" + std::filesystem::path(path).stem().string() + \"_gpu.bmp\";\n",
        "    if (!cv::imwrite(gpu_output, out)) {\n",
        "        std::cerr << \"Failed to save GPU image: \" << gpu_output << std::endl;\n",
        "    }\n",
        "\n",
        "    std::cout << \"Processed [\" << path << \"] with GPU kernel time: \" << kernel_ms << \" ms\" << std::endl;\n",
        "\n",
        "    // Clean up\n",
        "    CHECK_CUDA(cudaFree(db.d_input));\n",
        "    CHECK_CUDA(cudaFree(db.d_gauss));\n",
        "    CHECK_CUDA(cudaFree(db.d_laplace));\n",
        "    CHECK_CUDA(cudaFree(db.d_gkernel));\n",
        "    CHECK_CUDA(cudaEventDestroy(db.event_start));\n",
        "    CHECK_CUDA(cudaEventDestroy(db.event_stop));\n",
        "    CHECK_CUDA(cudaStreamDestroy(db.stream));\n",
        "}\n",
        "\n",
        "// Thread worker pool function\n",
        "void worker_func(const float* gaussKernel, const std::string& output_folder) {\n",
        "    while (true) {\n",
        "        std::string path;\n",
        "        {\n",
        "            std::lock_guard<std::mutex> lock(queue_mutex);\n",
        "            if (image_queue.empty())\n",
        "                break;\n",
        "            path = image_queue.front();\n",
        "            image_queue.pop();\n",
        "        }\n",
        "        process_image_gpu(path, gaussKernel, output_folder);\n",
        "        images_processed++;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    std::string input_folder = \"input_images\";\n",
        "    std::string output_folder = \"output_images\";\n",
        "    std::filesystem::create_directories(output_folder);\n",
        "\n",
        "    auto paths = get_image_paths(input_folder);\n",
        "    if (paths.empty()) {\n",
        "        std::cerr << \"No BMP images found in \" << input_folder << std::endl;\n",
        "        return 1;\n",
        "    }\n",
        "\n",
        "    for (const auto& p : paths)\n",
        "        image_queue.push(p);\n",
        "\n",
        "    float gaussKernel[9] = {1.f/16, 2.f/16, 1.f/16, 2.f/16, 4.f/16, 2.f/16, 1.f/16, 2.f/16, 1.f/16};\n",
        "\n",
        "    // ---- WARM-UP CALL ----\n",
        "    warm_up();\n",
        "\n",
        "    // Launch worker threads, limited by MAX_STREAMS\n",
        "    int thread_count = std::min(MAX_STREAMS, (int)paths.size());\n",
        "    std::vector<std::thread> workers;\n",
        "    for (int i = 0; i < thread_count; ++i) {\n",
        "        workers.emplace_back(worker_func, gaussKernel, output_folder);\n",
        "    }\n",
        "    for (auto& t : workers) t.join();\n",
        "\n",
        "    std::cout << \"All images processed. Total: \" << images_processed.load() << std::endl;\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "id": "hMRVxPf9u1_H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}